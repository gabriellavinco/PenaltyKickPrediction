{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WQn3K_fhtk3Y",
        "LDtjWTojt0ly",
        "PlRxC4ZnzgPF",
        "AQTuPt07Evr3",
        "D6fLUn3Nt6Tk",
        "edyTkjdMiQZw",
        "79S1DBAgyKYH",
        "MXGwNokqSjEX",
        "SmoXArU7QPbD",
        "s7tgsjA7QBL2"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EtFPdDPsDI75"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from numpy import array\n",
        "from numpy import vstack\n",
        "import json\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import LSTM, Dense,Dropout, LayerNormalization\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.models import Sequential\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frames_changable = 20"
      ],
      "metadata": {
        "id": "98ivG_vTDPkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coordinates = open(\"/content/gdrive/MyDrive/MASTERS_THESIS/yolov7pose/vid_coordsOG.txt\").read()"
      ],
      "metadata": {
        "id": "9t_msq4qDPgY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coordinates2 = open(\"/content/gdrive/MyDrive/MASTERS_THESIS/yolov7pose/vid_coords.txt\").read()"
      ],
      "metadata": {
        "id": "HRtaCjw8DPcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Original Footage"
      ],
      "metadata": {
        "id": "WQn3K_fhtk3Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coordinates = coordinates.replace(\"\\\\n\", \"\")"
      ],
      "metadata": {
        "id": "WObJnJjJNOPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vid_list = coordinates.split(\"{\")\n",
        "vid_list = vid_list[1:]"
      ],
      "metadata": {
        "id": "8uq08c2W4ekS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict = {}\n",
        "dict_list = []"
      ],
      "metadata": {
        "id": "JvjQzFuP8nWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(vid_list)):\n",
        "  data_dict = {}\n",
        "\n",
        "  vidname_coord_split = vid_list[i].split(\", 'coords': \")\n",
        "  vidname = vidname_coord_split[0]\n",
        "  vidname = vidname.replace(\"\\'vidname\\': \", \"\")\n",
        "  data_dict[\"video\"] = vidname\n",
        "\n",
        "  coords = vidname_coord_split[1]\n",
        "  coords = coords.replace(\"[array(\",\"\")\n",
        "  coords = coords.replace(\")]\",\"\")\n",
        "  coords = list(coords.split(\"],\")) # number of frames in video\n",
        "  # print(len(coords)) # number of frames in video\n",
        "  for j in range(len(coords)):\n",
        "    coords[j]  = list(coords[j].split(\",\"))\n",
        "    coords[j][0] = coords[j][0][2:]\n",
        "    coords[j] = [x.strip(']]}\"\"') for x in coords[j]]\n",
        "    coords[j] = [x.strip(' ') for x in coords[j]]\n",
        "    coords[j] = [float(value) for value in coords[j]]\n",
        "    # removes the z value \n",
        "    del coords[j][3-1::3]\n",
        "    # print(coords[j])\n",
        "    \n",
        "  data_dict[\"coords\"] = coords\n",
        "\n",
        "  dict_list.append(data_dict)"
      ],
      "metadata": {
        "id": "sSdHw2nn41bj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dict_list)"
      ],
      "metadata": {
        "id": "HIfk5wUoe4H9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_len = []\n",
        "for i in range(len(dict_list)):\n",
        "  frame_len.append(len(dict_list[i]['coords']))"
      ],
      "metadata": {
        "id": "A3zYRPvIm3nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in range(len(dict_list)):\n",
        "  frame_max = len(dict_list[i]['coords'])\n",
        "  # print(frame_max)\n",
        "  if frame_max > frames_changable+1:\n",
        "    cut_off = frame_max - (frames_changable + 2)\n",
        "    dict_list[i]['coords'] = dict_list[i]['coords'][cut_off+1:-1]\n",
        "  # elif frame_max == 18:\n",
        "  #   dict_list[i]['coords'] = dict_list[i]['coords'][:-1]\n",
        "  elif frame_max < frames_changable:\n",
        "    count +1\n",
        "    # dict_list[i]['coords'] = [val for val in dict_list[i]['coords'] for _ in (0, 1)]\n",
        "    # if len(dict_list[i]['coords']) > 16:\n",
        "    #   cut_off = len(dict_list[i]['coords']) - 17\n",
        "    #   dict_list[i]['coords'] = dict_list[i]['coords'][cut_off:-1]\n",
        "print(\"total number of videos omitted afer \")\n",
        "print(count)"
      ],
      "metadata": {
        "id": "k6bwmYmqVM8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final = []\n",
        "labels = []\n",
        "\n",
        "for a in range(len(dict_list)):\n",
        "  adjusted_final = {}\n",
        "  if len(dict_list[a]['coords']) == frames_changable:\n",
        "    coord = dict_list[a]['coords']\n",
        "    vid = dict_list[a]['video']\n",
        "    adjusted_final['coords'] = coord\n",
        "    adjusted_final['video'] = vid\n",
        "    adjusted_final['label'] = vid[1]\n",
        "    final.append(adjusted_final)\n",
        "    labels.append(vid[1])"
      ],
      "metadata": {
        "id": "hgVqjF-2bc88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(final)"
      ],
      "metadata": {
        "id": "uUg815Ye1-SA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(final[0]['coords'])"
      ],
      "metadata": {
        "id": "d2HexAFM2BJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coord_df = pd.DataFrame(final)"
      ],
      "metadata": {
        "id": "Eo6HEO28aaLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_length_listdf = list(\"F%d\" % i for i in range(1,frames_changable+1))\n"
      ],
      "metadata": {
        "id": "zn9uV_uWdNA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coord_df[frame_length_listdf] = pd.DataFrame(coord_df.coords.tolist(), index= coord_df.index)"
      ],
      "metadata": {
        "id": "DlOtAWVcbBXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coord_df"
      ],
      "metadata": {
        "id": "uI4IPawKc2gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XqarfBt6D74T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Mirrored Footage"
      ],
      "metadata": {
        "id": "LDtjWTojt0ly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coordinates2 = coordinates2.replace(\"\\\\n\", \"\")"
      ],
      "metadata": {
        "id": "qYayBk7DuVqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vid_list2 = coordinates2.split(\"{\")\n",
        "vid_list2 = vid_list2[1:]"
      ],
      "metadata": {
        "id": "AanobMmduVqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(vid_list2)"
      ],
      "metadata": {
        "id": "yJZK7UVP9VGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vid_list2[0]"
      ],
      "metadata": {
        "id": "qLFI6ipCinuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dict2 = {}\n",
        "dict_list2 = []"
      ],
      "metadata": {
        "id": "GLfIJ6OauVqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(vid_list2)):\n",
        "  data_dict2 = {}\n",
        "\n",
        "  vidname_coord_split2 = vid_list2[i].split(\", 'coords': \")\n",
        "  vidname2 = vidname_coord_split2[0]\n",
        "  vidname2 = vidname2.replace(\"\\'vidname\\': \", \"\")\n",
        "  data_dict2[\"video\"] = vidname2\n",
        "\n",
        "  coords2 = vidname_coord_split2[1]\n",
        "  coords2 = coords2.replace(\"[array(\",\"\")\n",
        "  coords2 = coords2.replace(\")]\",\"\")\n",
        "  coords2 = list(coords2.split(\"],\")) # number of frames in video\n",
        "  # print(len(coords)) # number of frames in video\n",
        "  for j in range(len(coords2)):\n",
        "    coords2[j]  = list(coords2[j].split(\",\"))\n",
        "    coords2[j][0] = coords2[j][0][2:]\n",
        "    coords2[j] = [x.strip(']]}\"\"') for x in coords2[j]]\n",
        "    coords2[j] = [x.strip(' ') for x in coords2[j]]\n",
        "    coords2[j] = [float(value) for value in coords2[j]]\n",
        "    # removes the z value \n",
        "    del coords2[j][3-1::3]\n",
        "    # print(coords[j])\n",
        "    \n",
        "  data_dict2[\"coords\"] = coords2\n",
        "\n",
        "  dict_list2.append(data_dict2)"
      ],
      "metadata": {
        "id": "xcJlUESAuVqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dict_list2)"
      ],
      "metadata": {
        "id": "h70F2s1RuVqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frame_len2 = []\n",
        "for i in range(len(dict_list2)):\n",
        "  frame_len2.append(len(dict_list2[i]['coords']))"
      ],
      "metadata": {
        "id": "nj6iSDanuVqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count2 = 0\n",
        "for i in range(len(dict_list2)):\n",
        "  frame_max2 = len(dict_list2[i]['coords'])\n",
        "  # print(frame_max)\n",
        "  if frame_max2 > frames_changable+1:\n",
        "    cut_off = frame_max2 - (frames_changable+2)\n",
        "    dict_list2[i]['coords'] = dict_list2[i]['coords'][cut_off+1:-1]\n",
        "  # elif frame_max2 == 18:\n",
        "  #   dict_list2[i]['coords'] = dict_list2[i]['coords'][:-1]\n",
        "  elif frame_max2 < frames_changable:\n",
        "    count2 +1\n",
        "    # dict_list[i]['coords'] = [val for val in dict_list[i]['coords'] for _ in (0, 1)]\n",
        "    # if len(dict_list[i]['coords']) > 16:\n",
        "    #   cut_off = len(dict_list[i]['coords']) - 17\n",
        "    #   dict_list[i]['coords'] = dict_list[i]['coords'][cut_off:-1]\n",
        "print(\"total number of videos omitted afer \")\n",
        "print(count2)"
      ],
      "metadata": {
        "id": "dFfctESpuVqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dict_list2[0])"
      ],
      "metadata": {
        "id": "v6L6DCDNuVqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final2 = []\n",
        "labels2 = []\n",
        "\n",
        "for a in range(len(dict_list2)):\n",
        "  adjusted_final2 = {}\n",
        "  if len(dict_list2[a]['coords']) == frames_changable:\n",
        "    coord2 = dict_list2[a]['coords']\n",
        "    vid2 = dict_list2[a]['video']\n",
        "    adjusted_final2['coords'] = coord2\n",
        "    adjusted_final2['video'] = vid2\n",
        "    # print(vid2)\n",
        "    adjusted_final2['label'] = vid2[2]\n",
        "    final2.append(adjusted_final2)\n",
        "    labels2.append(vid2[2])"
      ],
      "metadata": {
        "id": "OxOYnEnruVqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(final2)"
      ],
      "metadata": {
        "id": "yQjtns6OuVqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final2[0]"
      ],
      "metadata": {
        "id": "BWcuo3NKiQUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final2[200]['label']"
      ],
      "metadata": {
        "id": "kNXPGoYoxuXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " note to self, is it possible to then run lstm on only the body parts selected, like the legs and hips etc"
      ],
      "metadata": {
        "id": "xn_2V_tFxuXJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Combine the Two Versions"
      ],
      "metadata": {
        "id": "PlRxC4ZnzgPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coord2_df = pd.DataFrame(final2)"
      ],
      "metadata": {
        "id": "fphGa36RhCXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coord2_df[frame_length_listdf] = pd.DataFrame(coord2_df.coords.tolist(), index= coord2_df.index)"
      ],
      "metadata": {
        "id": "TRqBnsvAhCX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "coord2_df = coord2_df.replace(['R','L'],['L', 'R'])"
      ],
      "metadata": {
        "id": "990VMMdVhCX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df = pd.concat([coord_df,coord2_df])"
      ],
      "metadata": {
        "id": "Y4ToETHvliSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df = main_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "hegVr1thlzGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(main_df)"
      ],
      "metadata": {
        "id": "NVm1rkkfmLF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4QlWXdjuETXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df.head()"
      ],
      "metadata": {
        "id": "dMg69gjGEu1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df['label'].value_counts()"
      ],
      "metadata": {
        "id": "FqlxTf5brYzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizing the Pose Estimation Coords"
      ],
      "metadata": {
        "id": "AQTuPt07Evr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frame_len_list = ['F{}'.format(i) for i in range(1, frames_changable+1)]"
      ],
      "metadata": {
        "id": "rRvvc1a6TNeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_main_df = pd.DataFrame(columns = frame_len_list)"
      ],
      "metadata": {
        "id": "tYip48F6WMSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_main_df"
      ],
      "metadata": {
        "id": "oxtSEvhEs4aH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_nest = []"
      ],
      "metadata": {
        "id": "L1m8kswylMTV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_coordinates(row_i, col_j):\n",
        "    num_rows, num_cols = [567,960]\n",
        "    x = col_j/(num_cols - 1.)\n",
        "    y = row_i/(num_rows - 1.)\n",
        "    return x, y"
      ],
      "metadata": {
        "id": "0aadkCA-QP8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# position shifting dataframe\n",
        "for i in range(len(main_df)):\n",
        "    ind_fr_list = []\n",
        "    for y in range(3,frames_changable+3):\n",
        "        test_skeli = main_df.iloc[[i],[y]].values\n",
        "        test_skeli = np.array(test_skeli[0][0])\n",
        "        test_skeli = [test_skeli[i:i+2] for i in range(0, len(test_skeli), 2)]\n",
        "        test_skeli = np.array(test_skeli)\n",
        "        y,x = test_skeli.T\n",
        "\n",
        "        # 2 (Right?)\n",
        "        RS = test_skeli[1]\n",
        "        Rx, Ry = RS\n",
        "        # 5 (Left?)\n",
        "        LS = test_skeli[4]\n",
        "        Lx, Ly = LS\n",
        "\n",
        "        PSx = x - (Lx+Rx)/2\n",
        "        PSy = y - (Ly+Ry)/2\n",
        "\n",
        "        Sx = PSx/(960 - 1.)\n",
        "        Sy = PSy/(567 - 1.)\n",
        "\n",
        "        PS_coord = np.vstack((Sx,Sy)).T\n",
        "        PS_coord = list(PS_coord)\n",
        "        ind_fr_list.append(PS_coord)\n",
        "   \n",
        "    main_nest.append(ind_fr_list)\n",
        "    normalized_main_df.loc[len(normalized_main_df)] = ind_fr_list"
      ],
      "metadata": {
        "id": "_0_VtHGbOn_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_nest_arr = np.array(main_nest)"
      ],
      "metadata": {
        "id": "ZYEpRPfrM28B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_nest_arr = np.reshape(main_nest_arr, (791,20,34))"
      ],
      "metadata": {
        "id": "HOe_o_RYtH2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_nest_arr.shape"
      ],
      "metadata": {
        "id": "--oloKcYtJll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = list(main_df['label'])"
      ],
      "metadata": {
        "id": "P9v3irK_KUoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_labels = []\n",
        "\n",
        "# append the activity encoder to dictionary and list but reverse left and right\n",
        "for a in range(len(labels)):\n",
        "   # ['center', 'left', 'right']\n",
        "  if labels[a] == 'R': #0\n",
        "    dummy_labels.append([0,0,1])\n",
        "  elif labels[a] == 'C': #2\n",
        "    dummy_labels.append([0,1,0])\n",
        "  elif labels[a] == 'L': #1\n",
        "    dummy_labels.append([1,0,0])\n"
      ],
      "metadata": {
        "id": "skXBkGX-szl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unq = set(labels)"
      ],
      "metadata": {
        "id": "bvZVgmqSUWRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unq"
      ],
      "metadata": {
        "id": "2uV2CIjwUlXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x3a89VYcUuRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM preprocessing"
      ],
      "metadata": {
        "id": "D6fLUn3Nt6Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = array(dummy_labels)"
      ],
      "metadata": {
        "id": "P67p2sndwWJD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = main_nest_arr\n",
        "x = main_nest_arr"
      ],
      "metadata": {
        "id": "rJH0F_GRwa3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzjmsIRfRVQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cross Validation Split\n"
      ],
      "metadata": {
        "id": "edyTkjdMiQZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "XDrHQasL4s2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)"
      ],
      "metadata": {
        "id": "xoTaPvV6v6lS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape, x_test.shape)\n",
        "print(y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "id": "SI2OuSYgrhM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0]"
      ],
      "metadata": {
        "id": "2x1sypUHEZNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_timesteps, n_features, n_outputs = x_train.shape[1], x_train.shape[2], y_train.shape[1]"
      ],
      "metadata": {
        "id": "f5Auecp89yx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_outputs"
      ],
      "metadata": {
        "id": "YqQL2qZ67fh0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "N8oxZRvPP67-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qo1JO6qHP6LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Single Run LSTM"
      ],
      "metadata": {
        "id": "79S1DBAgyKYH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "log_dir = os.path.join('logs')\n",
        "tb_callback = TensorBoard(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "EL7ZwCqWje2X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
        "from keras.layers import Flatten, ConvLSTM2D, BatchNormalization\n",
        "from tensorflow.keras import Input\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import RepeatVector\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score\n",
        "import statistics\n",
        "from tensorflow import keras\n"
      ],
      "metadata": {
        "id": "PcM37PRfzKih"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(48, input_shape=(20,34)))\n",
        "model.add(Dropout(.4))\n",
        "\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# adagrad = keras.optimizers.Adagrad(learning_rate=0.001)\n",
        "# rms = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08,)\n",
        "# sgd = keras.optimizers.SGD(learning_rate=0.001, clipnorm=1.)\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "3oLO6Tm2jrfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "FAPDg4Ci_4Zh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=30, validation_split=0.3) # 150 epochs"
      ],
      "metadata": {
        "id": "JujFVYfM8BFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "#  \"Accuracy\"\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "# \"Loss\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GqEd_wgTKI8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "0JtRfcjn1bwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.argmax (y_pred, axis = 1)\n",
        "\n",
        "# # 0 = L, 1 = C, 2 = R\n",
        "y_test = np.argmax(y_test, axis=1)\n",
        "#Create confusion matrix and normalizes it over predicted (columns)\n",
        "result = confusion_matrix(y_test, y_pred , normalize='pred')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "-fkVfFgETENy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, digits=3))"
      ],
      "metadata": {
        "id": "UuqtqUwNS7ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "randomlist = []\n",
        "for i in range(0,159):\n",
        "  n = random.randint(0,2)\n",
        "  randomlist.append(n)\n",
        "print(randomlist)"
      ],
      "metadata": {
        "id": "jiqBnDsETHft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, randomlist, digits=3))"
      ],
      "metadata": {
        "id": "eqlMhwQFTBzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras Tuner "
      ],
      "metadata": {
        "id": "MXGwNokqSjEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner --upgrade"
      ],
      "metadata": {
        "id": "XZxAkPfzSq_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner\n",
        "from keras_tuner.engine.hyperparameters import HyperParameters\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "import keras.backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "import keras_tuner as kt\n",
        "from keras_tuner.tuners import RandomSearch\n"
      ],
      "metadata": {
        "id": "WdK09lt6Sq8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model1(hp):\n",
        "    early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(hp.Int('input_unit',min_value=16,max_value=64,step=16),input_shape=(x_train.shape[1],x_train.shape[2])))\n",
        "    model.add(Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.5,step=0.1)))\n",
        "    model.add(Dense(y_train.shape[1], activation=hp.Choice('dense_activation',values=['relu', 'sigmoid', 'softmax'],default='softmax')))\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "    rms = keras.optimizers.RMSprop(learning_rate=hp_learning_rate, rho=0.9, epsilon=1e-08,)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "lWU9_h7oSq3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner1= RandomSearch(\n",
        "        build_model1,\n",
        "        objective='accuracy',\n",
        "        max_trials=10,\n",
        "        executions_per_trial=1\n",
        "        )"
      ],
      "metadata": {
        "id": "F9KsJjrISq0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner1.search(\n",
        "        x=x_train,\n",
        "        y=y_train,\n",
        "        epochs=100,\n",
        "        validation_split=0.25)"
      ],
      "metadata": {
        "id": "LA9bRFD7SqsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner1.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "qWaxu867SyYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary()"
      ],
      "metadata": {
        "id": "RzFzDTgCSyWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner1.get_best_hyperparameters(5)"
      ],
      "metadata": {
        "id": "HJwQcPGvSyTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(best_hps[0])"
      ],
      "metadata": {
        "id": "O6JvlYXgS3Pl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_all = np.concatenate((x_train[:158], x_train[159:]))\n",
        "y_all = np.concatenate((y_train[:158], y_train[159:]))\n",
        "model.fit(x=x_all, y=y_all, epochs=100)"
      ],
      "metadata": {
        "id": "wJUthPezS3NQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner1.results_summary()"
      ],
      "metadata": {
        "id": "twRyEvlFS3Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_model.predict(x_test)"
      ],
      "metadata": {
        "id": "8Hz9aVLcS3IU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred.shape"
      ],
      "metadata": {
        "id": "m5a5DI-iS9fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Multiple Runs LSTM (50 runs)"
      ],
      "metadata": {
        "id": "SmoXArU7QPbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import statistics\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "scores = list()\n",
        "for r in range(50):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
        "  model = Sequential()\n",
        "  model.add(LSTM(48,  input_shape=(20,34)))\n",
        "  model.add(Dropout(.4))\n",
        "  model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "  # rms = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, epsilon=1e-08,)\n",
        "  # sgd = keras.optimizers.SGD(learning_rate=0.001, clipnorm=1.)\n",
        "  opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "  model.fit(x_train, y_train, epochs=30, validation_split=0.25)\n",
        "\n",
        "  y_pred = model.predict(x_test)\n",
        "  y_pred = np.argmax(y_pred, axis=1)\n",
        "  y_test = np.argmax(y_test, axis=1)\n",
        "  score = accuracy_score(y_test, y_pred)\n",
        "  scores.append(score)\n",
        "print(statistics.mean(scores))\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "-X2Uilv0KCmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scores"
      ],
      "metadata": {
        "id": "cuxzPGZdQHD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid')\n",
        "sns.kdeplot(np.array(scores), bw=0.5)"
      ],
      "metadata": {
        "id": "2T_-YAfvzTkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)\n",
        "y_pred = np.argmax (y_pred, axis = 1)\n",
        "\n",
        "# 0 = L, 1 = C, 2 = R\n",
        "y_test = np.argmax(y_test, axis=1)\n",
        "#Create confusion matrix and normalizes it over predicted (columns)\n",
        "result = confusion_matrix(y_test, y_pred , normalize='pred')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "L7y9QUQnJdPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "XYgELnbhcuhf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred, digits=3))"
      ],
      "metadata": {
        "id": "POts6cK9HaXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NNfOOhUSJLoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple Random Runs (50 runs)"
      ],
      "metadata": {
        "id": "s7tgsjA7QBL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = list()\n",
        "for r in range(50):\n",
        "  x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2)\n",
        "  randomlist = []\n",
        "  for i in range(0,159):\n",
        "    n = random.randint(0,2)\n",
        "    randomlist.append(n)\n",
        "  \n",
        "  y_test = np.argmax(y_test, axis=1)\n",
        "  score = accuracy_score(y_test, randomlist)\n",
        "  scores.append(score)\n",
        "print(statistics.mean(scores))\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "wRY7x81UPDyC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scores"
      ],
      "metadata": {
        "id": "Z_jIH7sqPDvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = confusion_matrix(y_test, randomlist , normalize='pred')\n",
        "print(result)"
      ],
      "metadata": {
        "id": "LmCkOAznX5sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_style('whitegrid')\n",
        "sns.kdeplot(np.array(scores), bw=0.5)"
      ],
      "metadata": {
        "id": "UA8DSmsCPDtr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}